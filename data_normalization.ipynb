{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tau_with_Deomographics.csv\n",
    "\n",
    "\n",
    "Here, the average of Tau between the left and reight cerebellum cortex are average. \n",
    "These values are subtracted from all columns and all negative values are set to 0.\n",
    "\n",
    "APOE4 normalization: Centers the values to 0 from [0,2] to [-1,1] by subtracting one from the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twd_df = pd.read_csv(\"./data/Tau_with_Demographics.csv\").drop(columns=['Unnamed: 0'])\n",
    "twd_df['Avg-Cerebellum-Cortex'] =  twd_df.loc[:,['Left-Cerebellum-Cortex', 'Right-Cerebellum-Cortex']].mean(axis=1)\n",
    "\n",
    "# Could also search for columns starting with 'ctx', 'Left', or 'Right'\n",
    "regions = ['ctx-rh-bankssts','ctx-rh-caudalanteriorcingulate','ctx-rh-caudalmiddlefrontal','ctx-rh-cuneus','ctx-rh-entorhinal','ctx-rh-fusiform',\\\n",
    "           'ctx-rh-inferiorparietal','ctx-rh-inferiortemporal','ctx-rh-isthmuscingulate','ctx-rh-lateraloccipital','ctx-rh-lateralorbitofrontal',\\\n",
    "           'ctx-rh-lingual','ctx-rh-medialorbitofrontal','ctx-rh-middletemporal','ctx-rh-parahippocampal','ctx-rh-paracentral','ctx-rh-parsopercularis',\\\n",
    "           'ctx-rh-parsorbitalis','ctx-rh-parstriangularis','ctx-rh-pericalcarine','ctx-rh-postcentral','ctx-rh-posteriorcingulate','ctx-rh-precentral',\\\n",
    "           'ctx-rh-precuneus','ctx-rh-rostralanteriorcingulate','ctx-rh-rostralmiddlefrontal','ctx-rh-superiorfrontal','ctx-rh-superiorparietal',\\\n",
    "           'ctx-rh-superiortemporal','ctx-rh-supramarginal','ctx-rh-frontalpole','ctx-rh-temporalpole','ctx-rh-transversetemporal','ctx-rh-insula',\\\n",
    "           'ctx-lh-bankssts','ctx-lh-caudalanteriorcingulate','ctx-lh-caudalmiddlefrontal','ctx-lh-cuneus','ctx-lh-entorhinal','ctx-lh-fusiform',\\\n",
    "           'ctx-lh-inferiorparietal','ctx-lh-inferiortemporal','ctx-lh-isthmuscingulate','ctx-lh-lateraloccipital','ctx-lh-lateralorbitofrontal',\\\n",
    "           'ctx-lh-lingual','ctx-lh-medialorbitofrontal','ctx-lh-middletemporal','ctx-lh-parahippocampal','ctx-lh-paracentral','ctx-lh-parsopercularis',\\\n",
    "           'ctx-lh-parsorbitalis','ctx-lh-parstriangularis','ctx-lh-pericalcarine','ctx-lh-postcentral','ctx-lh-posteriorcingulate','ctx-lh-precentral',\\\n",
    "           'ctx-lh-precuneus','ctx-lh-rostralanteriorcingulate','ctx-lh-rostralmiddlefrontal','ctx-lh-superiorfrontal','ctx-lh-superiorparietal',\\\n",
    "           'ctx-lh-superiortemporal','ctx-lh-supramarginal','ctx-lh-frontalpole','ctx-lh-temporalpole','ctx-lh-transversetemporal','ctx-lh-insula',\\\n",
    "           'Left-Cerebellum-Cortex','Left-Thalamus-Proper','Left-Caudate','Left-Putamen','Left-Pallidum','Left-Hippocampus','Left-Amygdala','Left-Accumbens-area',\\\n",
    "           'Left-VentralDC','Right-Cerebellum-Cortex','Right-Thalamus-Proper','Right-Caudate','Right-Putamen','Right-Pallidum','Right-Hippocampus',\\\n",
    "           'Right-Amygdala','Right-Accumbens-area','Right-VentralDC']\n",
    "\n",
    "# # Subtracts average from all columns, then makes negative values 0.\n",
    "twd_df.loc[:,regions] = twd_df.loc[:,regions].subtract(twd_df['Avg-Cerebellum-Cortex'], axis=0).clip(lower=0)\n",
    "# twd_df.loc[:,regions] = twd_df.loc[:,regions]/twd_df.loc[:,regions].max()\n",
    "twd_df.drop(columns=['Avg-Cerebellum-Cortex'], inplace=True)\n",
    "\n",
    "#APOE 4 Normalization [0,2] -> [-1,1]\n",
    "twd_df.loc[:, ['APOE4']] = twd_df.loc[:, ['APOE4']].subtract(1)\n",
    "\n",
    "# Remove unnamed columns\n",
    "remove = [x for x in twd_df.columns if 'Unnamed' in x.split(':')]\n",
    "twd_df.drop(columns=remove, inplace=True)\n",
    "\n",
    "# Remove merge columns\n",
    "remove = [x for x in twd_df.columns if 'merge' in x.split('_')]\n",
    "twd_df.drop(columns=remove, inplace=True)\n",
    "\n",
    "# Remove duplicate columns\n",
    "remove = [x for x in twd_df.columns if '1' in x.split('.')]\n",
    "twd_df.drop(columns=remove, inplace=True)\n",
    "\n",
    "# Remove columns with NANs \n",
    "# twd_df.dropna(inplace=True, axis=1) # removes APOE4 column (contains no NaNs)\n",
    "remove = ['FDG', 'PIB', 'AV45', 'ABETA', 'TAU', 'PTAU']\n",
    "twd_df.drop(columns=remove, inplace=True)\n",
    "\n",
    "# Add one hot encoding for sex, education level\n",
    "\n",
    "# Remove columns that are not int or float\n",
    "str_idx = [i for i in range(twd_df.shape[1]) if type(twd_df.iloc[0, i]) == str]\n",
    "twd_df.drop(twd_df.columns[str_idx], axis=1, inplace=True)\n",
    "\n",
    "# Remove rows with NaNs\n",
    "twd_df.dropna(axis=0, inplace=True)\n",
    "\n",
    "# Normalize between 0 and 1 for remaining columns (except for 'ml_stage' used in nexis and brain regions)\n",
    "adjust = [col for col in twd_df.columns if twd_df[col].max()>1 and col!='ml_stage' and col not in regions and col!='RID']\n",
    "twd_df.loc[:,adjust] = twd_df.loc[:,adjust]/twd_df.loc[:,adjust].max()\n",
    "\n",
    "# Remove ID and weighted tau data. Minimize leaking data\n",
    "twd_df = twd_df.drop(columns=['W_average_hippo','W_ADAS11','W_average_tau','W_average_frontal','W_average_temporal','W_average_parietal','W_average_occipital'])\n",
    "\n",
    "# # Save to CSV\n",
    "twd_df.to_csv('./data/Tau_with_Demographics_Normalized.csv')\n",
    "twd_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### connectome_mean80_fibercount.csv\n",
    "\n",
    "All values, normalized between 0 and 1 by dividing by the maximum value in the df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connectome = pd.read_csv(\"./data/connectome_mean80_fibercount.csv\")\n",
    "connectome /= connectome.max().max()\n",
    "\n",
    "# Save to CSV\n",
    "connectome.to_csv('./data/connectome_mean80_fibercount_normalized.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_200s",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
